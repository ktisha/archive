<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
   "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="ru" lang="ru">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>

<meta name="sprypayUrlChecker" content="sprypay_fpraOIA7CnzFuVkwTFol4GEMpK3RdzExgx4SCKayofR7wwGQvRBfNE2QUww9JV84_1763">

<title>Формы, языки представления, критерии и параметры сложности параллелизма</title>     <style>
	 .sps {
        padding-left: 20px;
        line-height: 20px;
	   padding:1px;
	   margin:0px;
     }

     .hed {
       color: #666666;
       font: bold;
       font-size: 14px;
       border: 1px solid;
	   padding:1px;
	   margin:0px;
     }

     .trhed {
       padding: 25px;
     }
	 
	 .td_arch {
	   margin:0px;
	   padding:5px;
	  }
	 
	 .in_journal {
	  border:3px solid #fff;
	 }

	 .in_journal:hover {
	  border:3px solid #aaaaaa;
	 }
	 
     .ndisp {
         display:none;
     }
     
	  </style>

<!--[if IE]>
<style>
.outer, .wrapper, .minwidth {
	zoom: 1;
}

</style>
<![endif]-->

<!--[if lt IE 7]>
<style>
.minwidth {
	border-left: 504px solid #fff;
}
.wrapper {
	margin-left: -504px;
	position: relative;
}
</style>
<![endif]-->

<link href="css/layout_2col_right_31.css" rel="stylesheet" type="text/css"/>	  

<link href="style.css" type="text/css" rel="stylesheet" />
<link rel="alternate" type="application/rss+xml" title="RSS" href="http://www.swsys.ru/rss">

<!--[if lte IE 7]>
<link href="css/patches/patch_2col_right_31.css" rel="stylesheet" type="text/css" />
<![endif]-->

    <script src="script/CalendarPopup.js"></script>


<script>

function submit_login() {
 if ( document.login_form.login.value != "" && document.login_form.password.value != "" ) { 
  document.login_form.activity.value = "AUTORIZ";
  document.login_form.submit();
  }
 else 
 {
 alert("Введите логин и пароль"); 
 document.login_form.username.focus();
 }
 
}

 function to_registry() {
	document.login_form.action = "event.php?page=registry";
    document.login_form.submit();
 }

 function to_search() {
    document.search_form.submit();
 }

</script>

</head>
<body>








<div id="page_margins">
	<div id="page">
		<div id="header">
			<div id="topnav">
				  <form action="event.php?page=search&order=date"  method="post" id="search-theme-form" name="search_form">
<div><div id="search" class="container-inline"><div class="form-item">
 <input type="text" maxlength="128" name="search" id="edit-search-theme-form-keys"  size="15" value="поиск..." title="Введите слова для поиска." class="form-text" onBlur="if ( this.value == '' ) this.value = 'поиск...';" onFocus="if ( this.value=='поиск...' ) this.value='';"/>
 <a href="#" onclick="Javascript: if ( document.search_form.search.value == 'поиск...' ) { alert('Введите поисковый запрос!') } else document.search_form.submit()">Найти</a>
</div>
</div>
</div></form>
				<div id="subsearch"><span><a href="index.php?page=extsearch">Расширенный поиск</a> / <a href="index.php?page=sitemap">Карта сайта</a></span></div> </div>
			<span style="cursor:pointer" onclick="Javascript:document.location = 'index.php'" class="zag">Международный журнал</span>
			<h1 style="cursor:pointer; width:auto" onclick="Javascript:document.location = 'index.php'">Программные продукты и системы</h1>
		   
			</div>
		<!-- begin: main navigation #nav -->
		<div id="nav"> <a id="navigation" name="navigation"></a>
			<!-- skiplink anchor: navigation -->			
		</div>
		<!-- end: main navigation -->
		<!-- begin: main content area #main -->
		<div id="main">
			<!-- begin: #col1 - first float column -->
			<div id="col1">
				<div id="col1_content" class="clearfix">
					<div id="menu" class="r-block">
						<h2>Разделы сайта</h2>
						<ul id="submenu">
						
						<li style="white-space:nowrap;margin-left:-15px"><a href="index.php?page=1">О журнале</a></li><li style="white-space:nowrap;margin-left:-15px"><a href="index.php?page=3">Редколлегия</a></li><li style="white-space:nowrap;margin-left:-15px"><a href="index.php?page=12">Научные направления</a></li><li style="white-space:nowrap;margin-left:-15px"><a href="index.php?page=9">Свежий выпуск</a></li><li style="white-space:nowrap;margin-left:-15px"><a href="index.php?page=19">Список авторов выпуска</a></li><li style="white-space:nowrap;margin-left:-15px"><a href="index.php?page=10">Архив выпусков</a></li><li style="white-space:nowrap;margin-left:-15px"><a href="index.php?page=11">Подписка</a></li><li style="white-space:nowrap;margin-left:-15px"><a href="index.php?page=5">Авторам и издателям</a></li>						
					  </ul>	
					</div>	

     
					<div id="login" class="mainborder r-block">
                    
                    <h2>Вход</h2>				
				   <form action="event.php?page=article"  method="post" id="login-form" name="login_form">
<div id="login-form-div">
	<div class="form-item"><input type="text" maxlength="128" name="login" size="15" value="" title="" class="form-text" /></div>
 <div class="form-item"><input type="password" maxlength="128" name="password" size="15" value="" title="" class="form-text"/></div>
 <input type="hidden" name="activity" />
 
        <label for="save_pas"><input type="checkbox" style="width:25px;border:none;" name="save_pas" id="save_pas" />Запомнить</label><br />

  <div id="login-button"><input style="border:none;width:46px;height:45px" type="image" src="images/login-button1.gif" onclick="submit_login();"></div> 
<!-- <input type="submit" /> -->
</div></form>
				 
				<span><a href="index.php?page=recovery">Забыли пароль?</a> / <a href="#" onclick="to_registry();">Регистрация</a></span>				  
                         
                 

                 
                 
				  </div>


                  
                  

           
  
  <div style="padding: 5px 0px 0px 45px">     
<script type="text/javascript"><!--
google_ad_client = "pub-6573451237838679";
/* Вторая страница право */
google_ad_slot = "0208394776";
google_ad_width = 120;
google_ad_height = 240;
//-->
</script>
<script type="text/javascript"
src="http://pagead2.googlesyndication.com/pagead/show_ads.js">
</script>                  
     </div>
     
      
				  
				  
				                    <div id="next-after" class="r-block">
                    <h2>Добавить в закладки</h2>
                    <script src="/ok2.js" type="text/javascript"></script>
                  </div>
                  
				  <div id="next-after" class="r-block">
					<h2>Следующий номер</h2>
					<div id="sled-nomer" class="floatbox"><span class="simv-nomer">№</span>1</div>
					<div id="sled-nomer-text">
					Выходит:<br/>
					<div> 18 Марта 2011 </div>
                     				  </div>
				 </div>
				  <div class="r-block" id="arh">
					<h2>Выпуски</h2>

 						<div class="god">2010</div><ul><li><a href="index.php?page=search&order=date&journal=92">№4 Декабрь 2010</a></li><li><a href="index.php?page=search&order=date&journal=91">№3 Сентябрь 2010</a></li><li><a href="index.php?page=search&order=date&journal=90">№2 Май 2010</a></li><li><a href="index.php?page=search&order=date&journal=89">№1 Март 2010</a></li></ul>
				
						<div align="center" style="margin-top:0px; padding:0px" ><a style="font-size:12px" href="index.php?page=10">все выпуски</a></div>
						<div align="center" style="margin-top:0px; padding:0px" ><a style="font-size:12px" href="index.php?page=all_article">все статьи</a></div>
				  </div>
				  
				  
				</div>

                  <div id="next-after" class="r-block">
                    <h2>Новости</h2>  
                                 
                        <p>     
                        <a href="index.php?page=show_news&id=117">В Международном университете природы, общества и человека (г. Дубна) предложен алгоритм генерации растущих сетей с нелинейным предпочтительным присоединением, конкуренцией и удалением узлов</a> [15.12.2010]
                        <br/>
                                     
                        <p>     
                        <a href="index.php?page=show_news&id=116">В Группе компаний «Генезис знаний» (г. Самара) предложено решение по построению и внедрению мультиагентной системы распределения производственных ресурсов МАС «Оптимизатор»</a> [08.12.2010]
                        <br/>
                                     
                        <p>     
                        <a href="index.php?page=show_news&id=115">В Волгоградском государственном техническом университете разработана модель обучающей системы в области автомобильного транспорта</a> [01.12.2010]
                        <br/>
                                                
                        <div style="text-align:center"><a href="index.php?page=show_news">читать все новости</a></div>
                        
                                          </div>

					<div class="r-block" style="text-align:center;padding:0px;margin:0px;">
					   <a style="text-decoration:none;" href="rss/"><img alt="RSS" title="RSS" src="images/rss.gif"/><br/>
						<div style="text-decoration:underline;display:inline">Подписаться на RSS</div></a>
					</div>
                    
                  

			</div>

       

			<!-- end: #col1 -->
			<!-- begin: #col3 static column -->
			<div id="col3">
				<div id="col3_content" class="clearfix"> <a id="content" name="content"></a>





<script>

            function go_event_comment(act, id)
            {
                 document.s_article.activity.value = act;
                 document.s_article.id.value = id;
                document.s_article.submit();
            }


            function go_event_vote(act, id)
            {
                 document.v_article.activity.value = act;
                 document.v_article.id.value = id;
                document.v_article.submit();
            }
            
            
</script>

<h2 style="margin-bottom:3px">Формы, языки представления, критерии и параметры сложности параллелизма</h2><div style="margin-bottom:10px"><strong>Forms, languages and complexity parameters of the parallelism</strong></div>Статья опубликована в выпуске журнала № 3 за 2010 год. [ 07.09.2010 ]<br/><strong>Аннотация:</strong><em style="font-size:8pt">Рассматриваются различные аспекты создания языков и сред параллельного программирования и реализации параллелизма в компьютерных системах</em><br /><strong>Abstract:</strong><em style="font-size:8pt">Main aspects of the parallelism in tasks and processes are considered in the paper. Their impact on parallel programming and implementation of parallelism on computer systems is analyzed.</em><table border="0" width="100%" style="width:100%;"> 
            <tr>
             <td colspan="2"><b>Авторы: </b><a href="index.php?page=infou&id=5881">Кутепов В.П. (vkutepov@appmat.ru)</a> - Московский энергетический институт (ТУ) Доктор технический наук Ph.D., <a href="index.php?page=infou&id=5882">Фальк В.Н. (vkutepov@appmat.ru)</a> - Московский энергетический институт (ТУ) Доктор технический наук Ph.D.</td>            
         </tr> 
            <tr>
             <td><b>Ключевые слова: </b><a href="index.php?page=infotg&id=1629">параллельные системы</a>, <a href="index.php?page=infotg&id=870">параллельное программирование</a>, <a href="index.php?page=infotg&id=1628">параллелизм</a><br /></td> 
           </tr>
            <tr>
             <td><b>Keywords: </b><a href="index.php?page=infotg&id=1629">parallel systems</a>, <a href="index.php?page=infotg&id=870">parallel programming</a>, <a href="index.php?page=infotg&id=1628">parallelism</a><br /></td> 
           </tr>   

 <tr>
             <td>Средний балл статьи: - <br />Всего комментариев: 0<br />Количество просмотров: 478<br />   
             </td> 
            <td align="right"><a target="_blank" href="/print/article_print.php?id=2551">Версия для печати</a></td>
         </tr>           
          </table>

<br/>

    
    
    <script>
      function set_size(vl) {
         document.getElementById('id_art').style.fontSize = vl;
      }
      function set_font(vl) {
         document.getElementById('id_art').style.fontFamily = "'" + vl + "'";
      }
    </script>
    
      <div style="width:100%;background:#E0E0E0;padding:5px;border:1px solid #D0D0D0">
         <form>
           Размер шрифта:
            <select name="f_size" onchange="set_size(this.value)">
               <option value="10px">10 px</option>
               <option value="12px" selected="selected">12 px</option>
               <option value="14px">14 px</option>
               <option value="16px">16 px</option>
               <option value="18px">18 px</option>
               <option value="24px">24 px</option>
            </select> &nbsp; &nbsp; &nbsp;
           Шрифт:
            <select name="f_name" onchange="set_font(this.value)">
               <option value="Arial">Arial</option>
               <option value="Trebuchet MS" selected="selected">Trebuchet MS</option>
               <option value="Times New Roman">Times New Roman</option>
               <option value="Verdana">Verdana</option>
               <option value="Arial Narrow">Arial Narrow</option>
               <option value="Tahoma">Tahoma</option>
            </select>
            
         </form>
        </div>
         <br />
    <table bgcolor="#FFFFFF"><tr><td><div id="id_art" style="font-size:12px;"><p>Компьютер сегодня &ndash; не только тонкий инструмент для решения сложнейших научно-техни&shy;ческих проблем, но и, пожалуй, главенствующее звено в процессе автоматизации всех сфер человеческой деятельности. Ал-Хорезми, выдающемуся мыслителю и математику Древнего Востока, пытавшемуся найти описание нечто общего и многократно повторяющегося в рациональной деятельности людей, было бы приятно узнать, насколько плодотворной оказалась его идея.</p>
<p>&nbsp;</p>
<p>Другому математику и выдающемуся инженеру фон Нейману повезло значительно больше  в воплощении алгоритмической парадигмы в реальность: его решение о представлении алгоритма в виде командной программы, хранящейся вместе с данными в памяти компьютера и выполняемой в виде упорядоченной последовательности операций над адресуемыми данными, оказалось настолько простым и плодотворным, что до сих пор продолжает жить в устройстве почти всех ком- пьютеров.</p>
<p>Сегодня нередко можно услышать критику в адрес строго последовательной концепции программы фон Неймана [1] как весьма ограниченной на общем фоне обычно параллельных и асинхронных процессов, с которыми мы сталкиваемся при программировании реальных задач. Но при этом игнорируется тот факт, что модель последовательной программы фон Неймана существенно упрощает архитектуру компьютера, в частности процессорную часть, оставаясь в то же время универсальной в алгоритмическом смысле. Последнее означает, что любые параллельно протекающие конструктивные процессы могут быть представлены в виде последовательной программы с сохранением их функционального значения как однозначных преобразователей входных данных в результаты.</p>
<p>Однако хорошо известно, что последовательные языки оказались совершенно неприспособленными, когда их пытались применить для описания моделирования работы сложных систем, где асинхронность и одновременность выполняемых процессов &ndash; норма, а не исключение. Их последовательная операционная семантика весьма ограничительная при программировании вычислений многих семантических объектов, таких, как, например, параллельные функции [2], или при вычислениях, в которых параллелизм является необходимым условием достижения требуемого качества алгоритма. Так, если ставить задачу минимизации времени вычисления значений функции на заданном множестве входных данных, используя при этом множество различных алгоритмов, естественным решением является их одновременное применение к каждому из данных и рассмотрение в качестве результата того из них, которое получено за наименьшее время.</p>
<p>Сегодня компьютерная индустрия может производить компьютерные, или вычислительные, системы (ВС) с сотнями тысяч самостоятельных компонентов, способных коллективно выполнять сложную работу, будь то вычислительные или управляющие процессы. Поэтому требуются совсем иные модельные, языковые и управляющие средства для их эффективного программирования и последующего параллельного выполнения.</p>
<p>Традиционный подход к решению этой непростой проблемы на основе расширения языков последовательного программирования с целью описания параллелизма и создание распараллеливающих компиляторов, как показывает практика, не дает нужных результатов.</p>
<p>Во-первых, возникает вопрос, зачем естественный параллелизм задач сначала надо (часто с большими усилиями) превращать в последовательные формы описания, а затем выявлять его при компиляции, что не всегда можно сделать в принципе. Во-вторых, какие должны быть языковые средства, чтобы сразу строить программу как параллельную.</p>
<p>Конечно, предыстория развития компьютеров, огромный багаж алгоритмов и программного обеспечения, созданных с использованием языков последовательного программирования, архитектура компьютера как последовательной машины еще долгое время будут обусловливать осторожность при всякой попытке кардинального изменения парадигмы, стиля и языков программирования.</p>
<p>Считается, что история параллелизма началась с работы [3], хотя уже фон Нейман хорошо понимал все ограничения, которые создает концепция последовательного программирования с точки зрения развития архитектуры компьютера и повышения его быстродействия. Опережающие устройства обработки команд в компьютерах 60-х годов stretch и БЭСМ-6, динамический анализ и одновременное выполнение независимых в программе команд в CDC-6600, арифметический конвейер, введение векторных команд в компьютерах Crey &ndash; наиболее значимые архитектурные нововведения, существенно увеличивающие быстродействие современных компьютеров. В среднем компьютер выполняет три-четыре операции одновременно благодаря усовершенствованию его процессора при выполнении последовательных программ.</p>
<p>Векторные команды многопроцессорной ВС ИЛЛИАК-4, возможность задания в последовательной программе ее независимо выполняемых ветвей (в принятой терминологии &ndash; нитей), реализованная в системах БЭРРОУЗ и ЭЛЬБРУС, параллельный ФОРТРАН &ndash; хорошо известные этапы практического перехода от последовательного программирования к параллельному и организации параллельных вычислений.</p>
<p>Все эти решения, хотя просты и имеют ограниченные возможности с позиции представления параллелизма, интересны тем, что дают средства, адекватные для представления параллелизма на задачном уровне, по крайней мере, вычислительных задач линейной алгебры.</p>
<p>Рекурсия как более мощное средство с точки зрения задания параллелизма, задание упреждающего параллелизма в программе и другие особенности реального параллелизма задач и процессов остались за пределами возможностей простых средств представления параллелизма.</p>
<p>Поскольку, как уже говорилось, так или иначе заданный параллелизм реализуется процессными средствами, управляющими одновременно протекающими при выполнении программы процессами, их взаимодействием, синхронизацией, порождением и др., естественным стало решение о перенесении этих средств в языковую среду (снова в расширение последовательной программы) с целью обеспечения в определенном смысле единообразной и в некотором смысле одноуровневой модели обращения с параллелизмом. Средства PVM, MPI, Multithreading [4,&nbsp;5] стали стандартными решениями, вообще говоря, достаточно низкоуровневого процессного описания параллелизма в последовательных программах. Да и OPEN MP мало что изменяет в этой концепции параллельного программирования, давая возможность программисту с помощью комментариев указывать участки последовательной программы, подлежащие параллельному выполнению.</p>
<p>Радикальный подход к решению проблемы параллелизма в работах по созданию комплексных средств параллельного программирования и управления параллельными процессами на компьютерных системах [6,&nbsp;7] состоит в комплексном решении трех взаимосвязанных задач.</p>
<p>Первая задача &ndash; создание высокоуровневых языков параллельного программирования с формальной денотационной, ориентированной на описание параллелизма на задачном уровне, и формальной операционной семантикой, строго регламентирующей процессы параллельного выполнения программы на компьютерных системах.</p>
<p>В основу такого языка в отличие от языков последовательного программирования может быть положен принцип явного отражения только информационной зависимости по данным между компонентами ее декомпозиции. Как следствие, независимые компоненты становятся источником параллелизма, реализуемого при выполнении программы [8,&nbsp;9]. Другой способ явного задания состоит в использовании функциональной нотации для отражения параллелизма через характеризацию как параллельных или последовательных операций композиции функций, используемых в языке. По этому принципу построен и реализован на компьютерных системах созданный авторами язык функционального параллельного программирования FPTL [10].</p>
<p>Вторая задача &ndash; создание среды, позволяющей упростить процесс разработки, отладки, прогонок на компьютерных системах и оптимизации параллельных программ [6,&nbsp;11]. В отличие от сред поддержки разработки последовательных программ экспериментальное исследование на реальной компьютерной системе параллельной программы с целью ее оптимизации принципиально важно для проектирования качественных и эффективных по времени выполнения и использованию ресурсов параллельных программ.</p>
<p>Наконец, третья задача &ndash; создание эффективных средств управления параллельными процессами, индуцируемыми при выполнении параллельных программ на масштабируемых и многоплатформенных компьютерных системах.</p>
<p>Эта задача состоит из двух подзадач: оптимального планирования процессов и оптимального управления загруженностью с целью оптимизации использования ресурсов компьютерной системы [6,&nbsp;7,&nbsp;11]. Успешно решенная задача (вместе с решением двух предыдущих задач) позволит существенно упростить и сделать независимым от конфигурации компьютерных систем проектирование параллельных программ для сложных вычислительных задач, задач распределенного управления, распределенной обработки информации и др.</p>
<p>Предмет обсуждения в данной статье &ndash; существенные для создания высокоуровневых языков параллельного программирования особенности, формы представления и характеристики параллелизма, а также критерии, по которым можно судить о сложности параллельных программ.</p>
<p>Формы и характеристики  параллелизма</p>
<p>Понятие параллелизма в вычислениях, управлении, коллективной работе и в других процессах связано с понятием процесса и одновременностью протекания актов и действий в процессах и их взаимодействием.</p>
<p>Поскольку практический интерес представляют процессы, реализующие определенные цели, семантика параллелизма часто имеет внепроцессное обоснование причин, по которым те или иные действия в процессах или сами процессы могут выполняться одновременно.</p>
<p>Систематизируем типы и формы параллелизма, возникающего в процессе решения задач, которые необходимо учитывать при создании методов и языков параллельного программирования и их реализации на ВС.</p>
<p>Параллелизм на процессном уровне</p>
<p>Работу компьютера, его операционной системы сегодня невозможно представить без понятий процесса, одновременности, синхронизации и взаимодействия процессов. Любая электронная схема компьютера построена на основе хорошо выверенных законов, как правило, параллельной работы и методов синхронизации ее взаимодействующих элементов.</p>
<p>По сути многие базисные понятия, используемые в широко известных моделях параллельных процессов &ndash; сетях Петри [11], моделях Р. Милнера [12], Ч. Хоара [13] и других, наследуются из языка описания электронных схем.</p>
<p>Последовательная и параллельная композиции процессов, их порождение и взаимодействие, синхронность и асинхронность &ndash; наиболее важные понятия, посредством которых описываются различные модели и языки описания параллельно протекающих и взаимодействующих друг с другом процессов.</p>
<p>Именно на базе этих моделей созданы и широко применяются процессные языковые стандарты и средства, используемые для параллельного программирования (PVM, MPI, Multithreading).</p>
<p>Для вычислительных задач, обработки информации, распределенного управления эти средства могут оказаться низкоуровневыми и в принципе ненужными, если есть развитые средства для управления процессами (в том числе параллельными) в компьютерных системах. Однако для описания работы операционной системы, процессов функционирования различных систем без этих средств не обойтись.</p>
<p>Очевидно, не все в многообразии поведения процессов может быть непосредственно выражено средствами данных процессных моделей и языковых средств, поскольку они предполагают строго определенные операции композиции элементарных процессов: объединение процессов, последовательную и параллельную композицию процессов, организацию циклов или/и рекурсивные определения как механизмы порождения процессов [12,&nbsp;13]. Как следствие, переходы из состояния в состояние в процессной модели однозначно определяются локально, на основе непосредственно взаимодействующих процессов. Однако уже такая часто применяемая команда, как kill (уничтожение процесса), не является локальной, и ее корректная реализация в принципе невозможна, если скорость порождаемых процессов больше скорости процесса их уничтожения (вдогонку).</p>
<p>Кроме того, анализ корректности параллельного процесса (параллельной программы), означающий отсутствие в нем (в ней) блокировок, гонок и т.п., &ndash; чрезвычайно сложная задача [4,&nbsp;14].</p>
<p>Тем не менее, процессные модели и языки необходимы, если речь идет о реализации параллелизма на практике.</p>
<p>Представление параллелизма  на задачном уровне</p>
<p>Декомпозиция и информационная независимость компонентов декомпозиции &ndash; основа отражения параллелизма при разработке программ решения сложных задач.</p>
<p>Идея построения языка, в программах которого явно указываются информационные связи (и только они) между ее компонентами (операторами, блоками, модулями), реализована в [8,&nbsp;9]. Параллелизм в программах на этом языке есть следствие информационной независимости их компонентов, он может быть эффективно реализован средствами программы в ВС [7].</p>
<p>Уточним понятие информационной зависимости компонентов Ki и Kj, которые вводятся при декомпозиции сложной задачи и ее представлении на этом языке. Будем полагать, что каждому компоненту К (оператору, функции и т.п.) однозначно сопоставлено множество In(K) входных данных, необходимых для того, чтобы К можно было начать выполнять, и множество выходных данных Out(K), которые вычисляет K. Семантическое значение того, что делает K, пока не затрагиваем.</p>
<p>Определение. Пусть в описании процесса решения задачи компонент Kj непосредственно информационно зависит от компонента Ki (Ki&rarr;Kj), если Kj использует хотя бы одно выходное значение Ki как входное. Транзитивное замыкание <img src="uploaded/image/2010-3/image045.png" alt="" width="36" height="20" />&nbsp;отношения непосредственной информационной зависимости позволяет говорить об информационной зависимости Kj от Ki, если Ki<img src="uploaded/image/2010-3/image045.png" alt="" width="36" height="20" />Kj.</p>
<p>Обозначим [Ki] множество всех входящих в описание задачи компонентов, которые зависят от Ki, и назовем [Ki] транзитивным классом Ki.</p>
<p>Если Ki<img src="uploaded/image/2010-3/image047.png" alt="" width="13" height="13" />[Ki], то Ki определен рекурсивно или принадлежит циклическому участку информационно зависимых от Ki компонентов, при этом Ki<img src="uploaded/image/2010-3/image045.png" alt="" width="36" height="20" />Ki.</p>
<p>Определение. Компоненты Ki и Kj информационно независимы, если Ki<img src="uploaded/image/2010-3/image050.png" alt="" width="13" height="16" />[Kj] и Kj<img src="uploaded/image/2010-3/image050.png" alt="" width="13" height="16" />[Ki].</p>
<p>Языки, в программах которых явно задаются связи, отражающие непосредственную информационную зависимость между их компонентами, и только они, как это сделано в языке граф-схемного потокового параллельного программирования (ЯГСПП) [8,&nbsp;9], позволяют одновременно эксплицировать параллелизм в программе как следствие информационной независимости компонентов. Более того, данный принцип построения программ дает возможность просто реализовать одновременное выполнение компонентов по готовности их входных данных, что практически нельзя эффективно сделать для последовательных программ. Кроме того, легко реализовать также потоковый принцип выполнения программы, когда она применяется к потоку в общем случае поступающих в реальном времени данных на ее входе.</p>
<p>Заметим, что условие независимости компонентов Ki и Kj последовательной программы определяется более сложно: In(Ki)&Ccedil;Out(Kj)=W&Ugrave; &Ugrave;In(Kj)&Ccedil;Out(Ki)=W&Ugrave;Out(Ki)&Ccedil;Out(Kj)=W, где Ω &ndash; пустое множество, а последний член конъюнкции отражает особенность обобществления переменных в программе и использование общей памяти при ее выполнении.</p>
<p>При построении языков, в программах которых информационная зависимость между компонентами задается явно, представление условных конструкций требует особого рассмотрения.</p>
<p>Определение. Допустим, что компонент программы Kj условно зависит от Ki, если Ki определяет необходимость использования выходных данных Kj после выполнения Ki.</p>
<p>На рисунке 1 приведен фрагмент граф-схемы программы, у которой компоненты K1, K2, K3 и K4 зависят от условия K. Условные входы и выходы компонентов изображаются как квадраты, а другие входы и выходы &ndash; в виде точек. При этом, если по левой связи передается значение &laquo;истина&raquo;, будут востребованы результаты выполнения компонентов K1 и K2; если значение &laquo;истина&raquo; передается по правой связи, будут использованы результаты выполнения компонентов K3 и K4.</p>
<p>Компоненты K1 и K3 для приведенного фрагмента граф-схемы могут выполняться одновременно (при наличии на их входах всех входных данных), причем с упреждением, поскольку только после выполнения К станет ясно, какие выходные данные компонента K1 или K3 потребуются при продолжении выполнения программы. В отличие от этого случая K2 или K4 будет выполняться только после завершения выполнения компонента К и компонентов K1 и K3, от которых они непосредственно информационно зависят.</p>
<p>Определение. Условную зависимость компонентов K1 и K3 от К, разрешающую упреждающее выполнение K1 и K3, назовем слабой, в отличие от этого условную зависимость K2 и K4 от К, разрешающую выполнение K2 или K4 только после выполнения K, назовем сильной.</p>
<p>Эквивалентными преобразованиями слабую зависимость можно трансформировать в сильную (см.&nbsp;рис.&nbsp;2) и наоборот, уменьшая или увеличивая параллелизм в программе.</p>
<p>Ясно, что, увеличивая распараллеливание программы за счет увеличения упреждающих вычислений, в модели параллельного выполнения программы должны быть механизмы явного различения компонентов, отнесенных к упреждающим вычислениям, чтобы всегда отдавать приоритет в выполнении неупреждающим компонентам с целью обеспечения корректности (достижение существующего результата).</p>
<p>Кроме того, по той же причине и с целью увеличения эффективности необходим механизм прерывания выполняемых с упреждением компонентов после того, как станет известно, что их результаты не потребуются.</p>
<p>Если параллельное выполнение программы организовано таким образом, что выполнение компонентов с упреждением подавляется, то такой параллелизм назовем строгим; в противном случае &ndash; упреждающим.</p>
<p>При потоковом параллельном выполнении программы также необходимо учитывать, что временной порядок поступающих на вход граф-схемы данных и вычисленных для них результатов может оказаться нарушенным. Введение в ЯГСПП [6, 9] тегирования данных, передаваемых между компонентами программы, позволяет обеспечивать взаимно однозначное соответствие между входными данными и выходными результатами выполнения программы.</p>
<p>Информационная независимость компонентов программы может выражаться не только явным заданием информационных связей между ними, но также косвенно посредством применения операций композиции компонентов, обладающих свойством параллельности.</p>
<p>Например, в языке FPTL используются четыре простые бинарные операции композиции функций, три из которых (*, &rarr; и &Aring;) являются параллельными и только одна операция &ndash; суперпозиция (&bull;) &ndash; последовательная [10, 11].</p>
<p>К примеру, функция f(g1(x),&nbsp;g2(x)) и условный оператор if p(x) then f1(x) else f2(x) на FPTL представляются в виде (g1*g2)&bull;f и (p&reg;f1)&Aring;(p&reg;f2), где операция &rarr; имеет семантику условной композиции функций, а операция композиции &Aring; &ndash; семантику объединения графиков ортогональных функций. Семантика операции композиции * &ndash; соединение кортежей значений функций, семантика операции &bull; &ndash; суперпозиция функций.</p>
<p><img src="uploaded/image/2010-3/image054.png" alt="Подпись:  
 

Рис. 1. Пример 
граф-схемы с условной
зависимостью
 компонентов	
Рис. 2. Условная 
зависимость компонентов, 
исключающая возможность
упреждающих вычислений" width="299" height="214" align="left" />В модели параллельного вычисления значений функций на FPTL только суперпозиция задает последовательный характер вычисления значений функций, к которым она применяется. Другие три операции композиции параллельны, более того, для операции &Aring; требуется параллельное или квазипараллельное вычисление значений функций, к которым она применяется.</p>
<p>Фрагмент граф-схемы на рисунке 1 имеет следующее функциональное представление на языке FPTL: K0&bull;((K&reg;K1)&bull;K2&Aring;(&Oslash;K&reg;K3)&bull;K4) и может быть приведен путем эквивалентных преобразований к максимально параллельной форме K0&bull;((K&reg;K1&bull;K2)&Aring;(&Oslash;K&reg;K3&bull;K4)), где К и &Oslash;К &ndash; ортогональные функции, соответствующие двум выходам компонента К на граф-схеме рисунка 1.</p>
<p>Рассмотренные языки параллельного программирования, на которых параллелизм представляется соответствующими конструкциями языка, назовем языками с явным заданием параллелизма.</p>
<p>В языках последовательного программирования параллелизм представлен неявно, и для его реализации нужны, с одной стороны, распараллеливающие компиляторы, выявляющие параллелизм, а с другой &ndash; языки параллельного программирования, в которые транслируются последовательные программы.</p>
<p>Коммутативный и некоммутативный &nbsp;параллелизм</p>
<p>Выделение этих форм параллелизма связано с закономерным вопросом: всегда ли компоненты программы, которые могут выполняться одновременно, можно выполнять последовательно в любом порядке. Ответ на этот вопрос имеет принципиальное значение, поскольку ресурсы ВС всегда ограничены и естественны ситуации, когда количество индуцируемых при выполнении программы и способных одновременно выполняться компонентов больше количества процессоров или компьютеров в ВС. В этом случае приходится упорядочивать выполнение этих компонентов, причем избранный порядок не всегда может быть произвольным.</p>
<p>Определение. Параллелизм назовем коммутативным, если допустим произвольный порядок компонентов программы, которые могут выполняться одновременно. В противном случае параллелизм будем называть некоммутативным.</p>
<p>Для условного оператора if&nbsp;p(x) then f1(x) else f2(x), хотя и есть возможность одновременного выполнения p(x), f1(x) и f2(x), однако, если начать вычисление с f1(x), длящееся неограниченно (функция f1 не применима к х), а значение p(x) ложно и f2(x) определено, то невозможно корректно выполнить условный оператор. Вычисление p(x) одновременно с f1(x) или f2(x), как и последовательное выполнение p(x), а затем f1(x) или f2(x), является корректным.</p>
<p>Сложнее обстоит дело с так называемыми параллельными функциями, корректное вычисление значений которых не может быть просто сведено к последовательной форме.</p>
<p>Рассмотрим пример известной в телефонии параллельной функции голосования f(g1(x), g2(x), g3(x)) [2], такой, что она определена, если при вычислении значений g1(x), g2(x) и g3(x) любые два из них определены и равны, причем значением функции f(g1(x), g2(x), g3(x)) в этом случае является одно из них; в противном случае значение функции не определено. Ясно, что параллельное вычисление значений функций g1(x), g2(x) и g3(x) при вычислении значения f(g1(x),&nbsp;g2(x),&nbsp;g3(x)) является естественным, а сведение к простому последовательному вычислению значений в любом порядке не гарантирует получения результата. Достаточно рассмотреть случай, когда вычисление одного из этих значений не определено и длится неограниченно, а два других определены  и равны. Только одновременное или квазипараллельное вычисление, например, путем разделения времени вычисления значений g1(x), g2(x) и g3(x), может обеспечить корректность вычисления значений функции f(g1(x),&nbsp;g2(x),&nbsp;g3(x)). Программирование таких функций на последовательных или параллельных языках требует особого подхода.</p>
<p>В функциональном языке FPTL представление и корректное вычисление подобного рода параллельных функций не вызывает проблем.</p>
<p>Приведенная функция голосования в FPTL может быть представлена в виде (g1*g2).eq&reg;g1&Aring; &Aring;(g2*g3).eq&reg;g2&Aring;(g1*g3).eq&reg;g3, где eq &ndash; бинарная функция проверки равенства аргументов.</p>
<p>Операционная семантика FPTL требует, чтобы при вычислении значения функции f1&Aring;f2, полученной путем &Aring;-композиции ортогональных функций f1 и f2 (заметим, что f1&Aring;f2&nbsp;&ndash;&nbsp;параллельная функция), вычисление значений f1(х) или f2(х) не откладывалось на неограниченное время, что достигается поочередным выделением им процессорного времени.</p>
<p>Кроме того, параллельные функции относятся к функциям с некоммутативным параллелизмом. В отличие от упреждающего параллелизма, когда значения компонентов программы, которые должны выполняться с упреждением, можно откладывать, для параллельных функций, как уже было сказано, это может приводить к тому, что вообще не будет получен результат выполнения программы.</p>
<p>Потоковый параллелизм  множества данных</p>
<p>Природа информационной независимости компонентов программы как необходимое условие ее распараллеливания рассмотрена выше.</p>
<p>Потоковый параллелизм имеет, скорее, организационную основу и восходит к конвейерной обработке, которая предполагает совмещение нескольких этапов последовательной обработки деталей (начало этому положил конвейерный способ организации технологического процесса, предложенный в начале прошлого века Тейлором). Конвейерный принцип выполнения команд в опережающем устройстве компьютера или операций в его арифметическом устройстве &ndash; примеры реализации конвейера в компьютерах.</p>
<p>Организуя поток данных на входе последовательной программы, получим классическую конвейерную схему, когда любой компонент программы, завершив выполнение поступивших данных, переходит к обработке следующих данных входного потока.</p>
<p>Линейный конвейер естественным образом можно расширить, введя разветвленную схему параллельной обработки, представляемую, например, в виде граф-схемы, как это сделано в ЯГСПП. Таким образом, легко достигается объединение параллельных процессов, индуцируемых при выполнении информационно независимых компонентов программы и разветвленной конвейерной (потоковой) обработки. Это существенно упрощает разработку параллельных программ для задач реального времени, в частности, распределенных управляющих систем.</p>
<p>Вместе с тем нет необходимости на каждой стадии конвейера обрабатывать только одну порцию входного потока данных. Можно использовать схему одновременного применения компонента программы к множеству всех поступивших на его вход данных, если для этого есть свободные процессоры или компьютеры в ВС.</p>
<p>Эта форма параллелизма реализована в ЯГСПП и в классификации Флинна соответствует способу организации параллельной обработки SIMD: один поток команд и множество потоков данных.</p>
<p>Другие схемы параллельной обработки (SISD, MISD, MIMD), введенные Флинном, скорее, раскрывают архитектурные особенности ВС, которые эти схемы параллельной обработки реализуют. SISD &ndash; последовательная обработка, MISD &ndash; типичная схема обслуживания запросов к БД, а MIMD &ndash; это то, что присуще работе любой многомашинной и многопроцессорной ВС.</p>
<p>Асинхронный и синхронный параллелизм</p>
<p>Оба эти понятия отражают отсутствие или наличие временных ограничений, накладываемых на следование событий в процессах, реализующих вычисления или управление.</p>
<p>Определение. Процесс, происходящий таким образом, что не накладывается никаких ограничений на длительность протекающих в нем актов (длительность выполняемых компонентов программы), называется асинхронным. Он также предполагает, что выполнение любого акта начинается сразу при выполнении условий, вытекающих из причинно-следственных связей его с другими актами, определяющими его готовность к выполнению. Если это условие нарушается, например, искусственно увеличивается время выполнения операторов, входящих в векторную конструкцию, то такой процесс называется синхронным.</p>
<p>Введение синхронизации часто упрощает описание и реализацию параллельных вычислений, как это очевидно для векторных и матричных задач. Описание и реализация асинхронных процессов существенно усложняют и то, и другое. Для этого достаточно ознакомиться с методами построения асинхронных схем, базирующихся на апериодических автоматах [15], или с моделью асинхронных вычислений значений функций на языке FPTL.</p>
<p>Заметим, что понятия асинхронности и параллельности не тождественны. Например, реализация процессов выполнения последовательной программы может быть асинхронной и в то же время не содержать параллелизма.</p>
<p>Параллелизм и проблемная среда</p>
<p>По-видимому, полезным может быть рассмотрение специфики задачных сред и особенностей построения в них параллельных алгоритмов и программ.</p>
<p>Очевидно, матричные задачи, сеточные схемы решения уравнений в частных производных и другие задачи линейной алгебры просты в распараллеливании, и параллельный Фортран, языки PVM, НОРМА, mpC и другие приспосабливались к этому типу задач. Стандарт OpenMP полезен для ручного распараллеливания программ, особенно, если они написаны для этого круга задач.</p>
<p>Совсем иные языковые средства требуются для описания сложных процессов, возникающих, например, в работе ВС, управлении, в системах массового обслуживания, для которых асинхронность и параллелизм являются неотъемлемыми свойствами. ЯГСПП создавался с ориентацией на эффективное параллельное программирование этого круга задач.</p>
<p>Поиск адекватных моделей и языковых средств, предназначенных для эффективного описания и реализации параллелизма в задачах различных проблемных сред, находит отражение в создании проблемно-ориентированных языков параллельного программирования: функциональных FPTL, Haskell [16], ML [17] и др., процессных MPI, Multithreading, логических Parlog и др.</p>
<p>Критерии и параметры  оценки параллелизма</p>
<p>Процесс программирования можно рассматривать как многоэтапный переход от задачи к представлению выбранного метода ее решения на конкретном языке программирования. Показатели, характеризующие качество разработанной программы, степень достижения предъявляемых к программе требований (времени вычисления, объему требуемой памяти и др.), в большей степени определяются методом решения задачи, выбором языка программирования и собственно уровнем программистского искусства, которое заключается в умелом использовании языковых средств для точного представления метода решения задачи и построения эффективной программы.</p>
<p>Для оценки сложности и качества параллельных программ используется целый ряд критериев и параметров.</p>
<p><img src="uploaded/image/2010-3/image056.png" alt="Подпись:  
Рис. 3. Схема 
параллельного вычисления n!" width="180" height="179" align="left" />Коэффициент ускорения</p>
<p>Коэффициент ускорения имеет принципиальное значение и обычно определяется как отношение времени выполнения параллельной программы на одном компьютере t(1) ко времени ее выполнения t(N) на ВС с N компьютерами или процессорами: C(N)=t(1)/t(N).</p>
<p>Согласно закону Амдала предельное ускорение решения задачи в параллельной форме на ВС с N узлами определяется соотношением: C(N)= =1/(a+(1-a)/N), где a &ndash; доля операций в программе, которые выполняются последовательно. Предельное ускорение при неограниченном N, очевидно, равно 1/a. В реальности ускорение меньше предельного из-за затрат времени на управление параллельным выполнением программы на ВС, реализацию обмена данными.</p>
<p>На практике более важно понять, как ведет себя ускорение в зависимости от сложности задачи и количества компьютеров (процессоров) N в ВС.</p>
<p>Пусть C(x1, x2, &hellip;, xk, N) есть функция, определяющая ускорение решения задачи в параллельной форме в зависимости от параметров x1, x2, &hellip;, xk сложности задачи и количества узлов N в ВС.</p>
<p>Для многих задач часто достаточно лишь определить предельное значение C(x1, x2, &hellip;, xk, N), если предполагать, что количество компьютеров или узлов ВС не ограничено (в этом случае не возникает задержек при выполнении параллельной программы из-за отсутствия необходимых ресурсов), и не учитывать системные издержки на организацию выполнения параллельной программы на ВС (обменные взаимодействия, управление и др. [7]). Именно при этих предположениях обычно определяется коэффициент ускорения для многих методов и параллельных программ.</p>
<p>В качестве параметров x1, x2, &hellip;, xk, характеризующих вычислительную сложность задачи, во многих случаях используются параметры, определяющие размерность задачи, которые одновременно являются и аргументами программы, представляющей метод ее решения.</p>
<p>Рассмотрим пример простой задачи вычисления значений n!, используя для этого параллельный метод разбиения отрезка [1&cedil;n] пополам, по программе: Fact(i, j)=1 if i=j else Fact(i,&euml;(i+j)/2&ucirc;)&acute; &acute;Fact(&euml;(i+j)/2&ucirc;+1, j)), где &euml;a&ucirc; &ndash; ближайшее целое  к a. Очевидно, что F(1, n)=n!.</p>
<p>Если попытаться реализовать процесс вычисления значения n! по этой программе, используя все возникающие возможности распараллеливания, нетрудно показать, что этот процесс следует схеме, изображенной на рисунке 3.</p>
<p>Параметр n (аргумент приведенной выше функции) характеризует вычислительную сложность задачи, а коэффициент C(n) (при неограниченном числе узлов ВС) ведет себя, как O(n/log2n), и при неограниченном увеличении n стремится к бесконечности.</p>
<p>Таким образом, с усложнением задачи (увеличением n) можно неограниченно со&shy;кращать время выполнения этой программы при условии неограниченных ресурсов.</p>
<p>Можно привести множество примеров других задач (перемножение матриц, решение систем линейных уравнений и др.), для которых с увеличением их сложности коэффициент ускорения возрастает неограниченно.</p>
<p>Параллельные программы такого типа назовем программами с неограниченным параллелизмом.</p>
<p>Глубина и степень распараллеливания  &nbsp;  Введем еще один параметр, определяющий глубину распараллеливания метода (или представляющего его алгоритма) и интуитивно характеризующий в среднем вычислительную сложность компонентов параллельной программы, которые рассматриваются как ее самостоятельные части и могут выполняться одновременно. В литературе этот параметр часто называется зернистостью параллелизма.</p>
<p>Определение. Глубиной распараллеливания d назовем усредненную вычислительную сложность компонентов, которые рассматриваются в параллельной программе как самостоятельные процессы, идентифицируемые и планируемые при ее выполнении на ВС.</p>
<p>Обратную к d величину определим как степень распараллеливания, характеризующую усредненное количество компонентов параллельной программы, которые могут выполняться одновременно.</p>
<p>Рассмотрим простой пример перемножения квадратных матриц размера n и определим предельный коэффициент ускорения процесса параллельного решения этой задачи для различных d и неограниченного количества компьютеров в ВС:</p>
<p>1)&nbsp;&nbsp; d1 &ndash; сложность вычисления одной строки результирующей матрицы, а степень распараллеливания &ndash; одновременное вычисление всех строк матрицы: <img src="uploaded/image/2010-3/image058.png" alt="" width="220" height="51" />,</p>
<p>где tум и tсл &ndash; время выполнения операций умножения и сложения соответственно;</p>
<p>2)&nbsp;&nbsp; d2 &ndash; сложность вычисления одного элемента результирующей матрицы, а степень распараллеливания &ndash; одновременное вычисление всех элементов результирующей матрицы:</p>
<p><img src="uploaded/image/2010-3/image060.png" alt="" width="225" height="48" />;</p>
<p>3)&nbsp;&nbsp; d3 &ndash; сложность операции умножения, а степень распараллеливания &ndash; одновременное выполнение всех операций умножения при одновременном вычислении всех элементов результирующей матрицы:</p>
<p><img src="uploaded/image/2010-3/image062.png" alt="" width="257" height="48" />, где r1 &ndash; некоторая константа, r1&pound;1; O(x) &ndash; близкое к x значение;</p>
<p>4)&nbsp;&nbsp; d4 &ndash; усредненная сложность выполнения операции умножения и параллельного вычисления суммы <img src="uploaded/image/2010-3/image064.png" alt="" width="123" height="33" />&nbsp;при вычислении элементов результирующей матрицы; степень распараллеливания определяется исходя из условия одновременного выполнения всех операций умножения при последующем параллельном вычислении приведенной выше суммы делением отрезка [1&cedil;n] пополам (см. пример параллельного вычисления факториала выше):</p>
<p><img src="uploaded/image/2010-3/image066.png" alt="" width="271" height="48" />, где r2&pound; r1.</p>
<p>Нетрудно заметить, что во всех четырех случаях коэффициент ускорения неограниченно растет с увеличением n. Однако производная (ускорение) этого роста различна для разных d, например, для d1, d2, d3 коэффициент ускорения растет как O(n), O(n2) и O(r1&times;n3) соответственно.</p>
<p>Обратим внимание, что степень распараллеливания ведет себя как неубывающая функция в зависимости от величины 1/d и всегда существует ее предельное значение, определенное предельной и всегда ограниченной глубиной распараллеливания.</p>
<p>Варьирование степени распараллеливания задачи чрезвычайно важно при оптимизации процесса выполнения ее на ВС с позиции минимизации времени выполнения и использования ресурсов. Это может происходить как на стадии разработки параллельной программы и ее статическом планировании на ВС, так и на стадии выполнения, когда динамически варьируется степень распараллеливания с целью увеличения фронта готовых к выполнению процессов, что ведет к увеличению загруженности ВС.</p>
<p>Интенсивность  обменных взаимодействий  &nbsp;  Эффективность параллельной работы ВС также существенно зависит от пропускной способности коммуникаций и интенсивности обменных взаимодействий между ее компонентами в процессе выполнения параллельной программы. Поэтому важно понять, каким образом при изменении степени распараллеливания будет изменяться интенсивность обменных взаимодействий при выполнении программы на ВС.</p>
<p>Определение. Определим интенсивность обменных взаимодействий для параллельной программы при глубине распараллеливания d как функцию <img src="uploaded/image/2010-3/image068.png" alt="" width="112" height="23" />, где n &ndash; количество обменных взаимодействий при выполнении параллельной программы заданной сложности <img src="uploaded/image/2010-3/image070.png" alt="" width="118" height="21" />&nbsp;на ВС с N узлами.</p>
<p>Если количество узлов ВС N таково, что задержек при выполнении параллельной программы не существует из-за недостатка компьютеров или процессоров в ВС, будем обозначать l(<img src="uploaded/image/2010-3/image072.png" alt="" width="14" height="15" />, d) как предельное значение интенсивности обменов.</p>
<p>Легко проверить следующее: для рассмотренных примеров параллельного вычисления n! и  перемножения матриц, если полагать, что они осуществляются на ВС с разделенной памятью,  l(<img src="uploaded/image/2010-3/image072.png" alt="" width="14" height="15" />, d) ведет себя в зависимости от <img src="uploaded/image/2010-3/image072.png" alt="" width="14" height="15" />&nbsp;и d практически так же, как и степень распараллеливания.</p>
<p>При увеличении степени распараллеливания до определенного предела путем изменения d время выполнения параллельной программы сначала уменьшается. Однако при этом увеличивается интенсивность обменов между узлами ВС и при d</p>
<p>Может показаться, что параллельные вычисления на ВС с общей памятью устраняют проблему снижения эффективности их работы из-за обменных взаимодействий между компьютерами. Однако достаточно рассмотреть пример вычисления значений функции n! в абсолютно параллельной форме согласно рисунку 1, чтобы понять: при реализации этой стратегии к общей памяти одновременно могут обращаться порядка n/2 команд.  С увеличением n ограниченная пропускная способность системы &laquo;процессоры&ndash;память&raquo; станет узким местом, что существенно уменьшит эффект от распараллеливания.</p>
<p>Более того, для параллельной программы, как правило, требуется гораздо больший объем оперативной памяти (в рассмотренном примере порядка n/2 ячеек памяти), а возникающие обмены с дисковой памятью могут свести к нулю эффект от распараллеливания.</p>
<p>Использование ресурсов  &nbsp;  На практике при организации параллельных вычислений важно знать не только ускорение, получаемое при выполнении параллельной программы на реальной ВС, но и то, как при этом используются ее ресурсы.</p>
<p>Для определения эффективности применения ресурсов обычно используют отношение C(x1, x2, &hellip;, xm, N)/N, причем часто считают, что это отношение не может быть больше единицы, полагая, что ускорение не может быть больше N &ndash; количества узлов, процессоров и компьютеров ВС.</p>
<p>В действительности это не так, поскольку для сложных задач, требующих большого объема памяти, ускорение может быть больше N. Это связано с тем, что для сложных задач время выполнения программы на одном компьютере (предполагая, что его память не больше объема памяти всех компьютеров ВС) может существенно увеличиться из-за большой интенсивности обменов между оперативной памятью и дисковой.</p>
<p>Более точное представление о реальном использовании ресурсов, в частности узлов ВС, дает усредненное значение их загруженности на интервале T выполнения параллельной программы: <img src="uploaded/image/2010-3/image074.png" alt="" width="83" height="37" />, где Li(t), i=1, 2, &hellip;, N &ndash; загруженность i-го узла. Обычно о загруженности ВС судят по загруженности только ее процессоров, что часто оправдано для вычислительных задач.</p>
<p>Однако задача может быть такой, что в ее программе основную часть времени занимает работа с периферией (ввод/вывод) или обработка сложных массивов данных. В этих случаях акцент смещается в сторону организации эффективного управления памятью, портами, периферией и др. В [7] при исследовании проблемы управления параллельной работой ВС показано, что ее эффективность существенно зависит от интенсивности индуцируемых при выполнении программ команд ввода/вывода, обмена с дисковой памятью, в том числе из-за возникающего обмена страницами между оперативной и дисковой памятью по причине недостатка первой, а также из-за обмена данными между узлами.</p>
<p>Если степень загруженности любого из указанных трактов, то есть действующего в нем оборудования, определяется как отношение &lambda;/&mu;, где &lambda; &ndash; интенсивность входного потока, &mu; &ndash; интенсивность его обслуживания, и это отношение оказывается больше единицы, данный тракт становится узким местом, резко снижающим общую производительность параллельной работы ВС.</p>
<p>Интересно проследить общий характер изменения показателя эффективности использования ресурсов ВС для задачи заданной сложности с увеличением N &ndash; количества узлов ВС.</p>
<p>Очевидно, если не изменяется глубина распараллеливания и сохраняется общая схема организации выполнения параллельной программы на ВС, этот показатель сначала должен увеличиваться (точнее, не уменьшаться) с увеличением N. Однако всегда будет существовать некоторое оптимальное значение N, больше которого уже нельзя уменьшить время выполнения программы (нужна задача большей сложности или требуется уменьшение глубины распараллеливания).</p>
<p>Можно сделать вывод, что при построении эффективных параллельных программ необходимо не только уделять серьезное внимание разработке параллельных методов решения задач, но и уметь их анализировать и приспосабливать к масштабу ВС и ее техническим возможностям для достижения максимального эффекта.</p>
<p>Подобно всяким изобретениям языки программирования, конечно, имеют прикладное значение и их создание и развитие обусловлены как реальной практикой применения, так и бурным развитием вычислительной техники. Состоявшийся долгожданный переход компьютерной индустрии к широкому производству компьютерных систем (кластеров, сетей и т.п.), насчитывающих тысячи и даже сотни тысяч компонентов, заставляет разработчиков срочно решать задачу создания языковых и управляющих средств для эффективного применения такого рода систем. В статье авторы попытались обозначить реперные точки, вокруг которых происходит объективное столкновение различающихся и часто противоположных подходов к созданию языков и сред параллельного программирования.</p>
<p>Очевидно, что созданное фирмами-разработ&shy;чиками программное обеспечение пока далеко от того, чтобы сделать эффективными процессы разработки параллельных программ и их выполнение на различных компьютерных системах.</p>
<p>Уже разработано огромное количество языков последовательного программирования и операционных средств, и понятно, что объектно-ориенти&shy;рованное программирование &ndash; лишь очередной этап развития. Скорее всего, это касается создания и повышения уровня языков и сред параллельного программирования, а также создания теоретической базы и практической реализации методов и средств управления процессами в больших компьютерных системах.</p>
<p>&nbsp;  Литература</p>
<p>1.&nbsp;&nbsp; Backus J. Can programming be liberated from the von Neuman style? Communication of ACM, 1978, № 1, pp. 613&ndash;641.</p>
<p>2.&nbsp;&nbsp; Трахтенброт Я.Б. Обогащение алгоритмических языков параллельными функциями: Автореф&hellip; к.ф.-м.н. Н.: ИМ СО АН СССР, 1978.</p>
<p>3.&nbsp;&nbsp; Gill S. Parallel programming. The computer journal, 1958, № 1, pp. 2&ndash;10.</p>
<p>4.&nbsp;&nbsp; Грегори Эндрюс Р. Основы многопоточного параллельного и распределенного программирования. M.: Изд. дом &laquo;Вильямс&raquo;, 2003. С. 1&ndash;506.</p>
<p>5.&nbsp;&nbsp; Хьюз К. и Хьюз Т. Параллельное и распределенное программирование. М.&ndash;СПб&ndash;К., 2004. С. 1&ndash;667.</p>
<p>6.&nbsp;&nbsp; Кутепов В.П. Об интеллектуальных компьютерах и больших компьютерных системах нового поколения // Изв. РАН. ТиСУ. 1996. № 5.</p>
<p>7.&nbsp;&nbsp; Кутепов В.П. Интеллектуальное управление процессами и загруженностью в вычислительных системах // Изв. РАН. ТиСУ. 2007. № 5. С. 58&ndash;73.</p>
<p>8.&nbsp;&nbsp; Котляров Д.В., Кутепов В.П., Осипов М.А. Граф-схем&shy;ное потоковое программирование и его реализация на компьютерных системах // Изв. РАН. ТиСУ. 2005. № 1. С. 75&ndash;96.</p>
<p>9.&nbsp;&nbsp; Kutepov V.P., Malanin V.M., Pankov N.A. An approach to the development of programming software for distributed computing and information processing systems. ICSOFT-08, International conference on software and data technologies, Porto, Portu- gal, 2008, pр. 83&ndash;90.</p>
<p>10.Бажанов С.Е., Кутепов В.П., Шестаков Д.А. Язык функционального параллельного программирования и его реализация на кластерных системах // Изв. РАН. Программирование. 2005. № 5.</p>
<p>11.Бажанов С.Е., Воронцов М.Н., Кутепов В.П. Структурный анализ и планирование процессов параллельного вы- полнения функциональных программ // Изв. РАН. ТиСУ. 2005. № 6. С. 111&ndash;126.</p>
<p>12.Milner R. A calculus for communicating systems. Lecture notes in computing science. Springer &ndash; Verlag, New York, 1980. Vol. 92.</p>
<p>13.Хоар Ч. Взаимодействующие последовательные процессы. М.: Из-во &laquo;Мир&raquo;, 1989. С. 240.</p>
<p>14.Журнал для разработчиков MSDN Magazine. М.: 2008, 11(83). URL: www.microsoft.com/rus/msdn/magazine (дата обращения: 16.04.2010).</p>
<p>15.Апериодические автоматы; под ред. В.И. Варшавского. М.: Наука, 1976. С. 424.</p>
<p>16.Jones S.T. Peyton. The implementation of functional programming languages. Prentice Hall, 1987.</p>
<p>17.Milner R. The standard ML core language. Polymorphism // The ML/LCF/ Hope Newsletter, October, 1985. Vol. 2. № 2.</p></div><br /></td></tr></table><table border="0" width="100%" style="width:100%;">
                   <tr>
                      <td><b>Постоянный адрес статьи: http://swsys.ru/index.php?page=article&id=2551</b></td>
                      <td align="right"><a target="_blank" href="/print/article_print.php?id=2551">Версия для печати</a></td>
                   </tr>
                   <tr>
                      <td><b>Статья опубликована в выпуске журнала № 3 за 2010 год.</b></td>                      
                                  </tr>            <tr><td><a href="http://swsys.ru/pay/form.php?journal=91">Электронная подписка на данный выпуск в формате PDF</a>            </tr></td>              
          </table><br /><a href="javascript:history.back();">Назад, к списку статей</a><br /><br />Хотите оценить статью или опубликовать комментарий к ней - <a href="http://swsys.ru/index.php?page=registry">зарегистрируйтесь</a><br /><br />




				
				<div id="ie_clearing">&nbsp;</div>
				<!-- End: IE Column Clearing -->
				
			</div>
			<!-- end: #col3 -->
            
         
            
		</div>
        
		<!-- end: #main -->
		<!-- begin: #footer -->


         </div>


		<div id="footer">

			<div class="black">Журнал зарегистрирован в комитете РФ по печати</div><div style="margin:0px; padding:0px; line-height:16px">
			Свидетельство о регистрации средства массовой информации № 013831 от 26.11.99 г.<br />
			Решение Президиума Высшей аттестационной комиссии Министерства образования и науки РФ от 19.02.2010 г. (о внесении в Перечень ведущих рецензируемых научных журналов и изданий, в которых должны быть опубликованы основные научные результаты диссертаций на соискание ученых степеней кандидата и доктора наук).<br />
&copy; Все права на авторские материалы охраняются в соответствии с законодательством РФ. Перепечатка возможна только с разрешения редакции. При цитировании материалов обязательна ссылка на Международный журнал "Программные продукты и системы" (для on-line проектов обязательна гиперссылка).</div>
			

			<div style="margin-top:15px;float:left">
<!--LiveInternet counter--><script type="text/javascript"><!--
document.write("<a href='http://www.liveinternet.ru/click' "+
"target=_blank><img src='http://counter.yadro.ru/hit?t26.1;r"+
escape(document.referrer)+((typeof(screen)=="undefined")?"":
";s"+screen.width+"*"+screen.height+"*"+(screen.colorDepth?
screen.colorDepth:screen.pixelDepth))+";u"+escape(document.URL)+
";"+Math.random()+
"' alt='' title='LiveInternet: показано число посетителей за"+
" сегодня' "+
"border=0 width=88 height=15><\/a>")//--></script><!--/LiveInternet-->
			</div>

			<div align="right" style="margin:15px">
               <a target="_blank" href="http://www.cps.tver.ru">Сайт разработан в <span>НИИ &laquo;ЦЕНТРПРОГРАММСИСТЕМ&raquo;</span></a><br />
               <a href="http://swsys.ru/index.php?page=17">Информация о сайте</a>
            </div>

		</div>		
		<!-- end: #footer -->



	</div>

</div>



<style>

.reklama {
    color: #666;
   font-size:11px;
   font-family:Arial;
  padding-bottom:20px;
}
.reklama a {
    color: #666;
   text-decoration:underline;
}
.reklama a:hover {
    color: #000;
   text-decoration:none;
}
 

@media print {
  .reklama {
      display:none;
  }
}

</style>




</div>


 






<script type="text/javascript">
/*
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
*/
</script>
<script type="text/javascript">
/*
try {
var pageTracker = _gat._getTracker("UA-9821437-1");
pageTracker._trackPageview();
} catch(err) {}
*/
</script>

</body>
</html>
